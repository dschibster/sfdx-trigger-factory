{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SFDX Trigger Factory The SFDX Trigger Factory Framework is the trigger pattern in use in most organizations that are being consulted by mindsquare AG. It is meant to be scalable from very small adjustments and automations to big, enterprise-level patterns. Due to the Trigger Framework only delivering logistics, its possible to add logic wherever you see fit. Additonally, the trigger factory works off of Custom Metadata to fire its triggers, which means that your development teams can work agnostically from each other, e.g. for different Record Types for each object, enabling package-based development without dependency issues. See in the sidebar of this documentation on what this framework can and can't do, and how to use it to the fullest.","title":"Introduction"},{"location":"#sfdx-trigger-factory","text":"The SFDX Trigger Factory Framework is the trigger pattern in use in most organizations that are being consulted by mindsquare AG. It is meant to be scalable from very small adjustments and automations to big, enterprise-level patterns. Due to the Trigger Framework only delivering logistics, its possible to add logic wherever you see fit. Additonally, the trigger factory works off of Custom Metadata to fire its triggers, which means that your development teams can work agnostically from each other, e.g. for different Record Types for each object, enabling package-based development without dependency issues. See in the sidebar of this documentation on what this framework can and can't do, and how to use it to the fullest.","title":"SFDX Trigger Factory"},{"location":"features/","text":"Features The framework comes with a variety of features that you can leverage to your liking. Trigger collections delivered to your class The virtual class TriggerHandlerExtension that is your Trigger Handler class base offers you the following variables: triggerNew triggerNewMap triggerOld triggerOldMap To use in your bulkBefore / bulkAfter calls (as they are already leveraged in the single-record methods). This makes it possible to mock a run of a trigger by simply filling in these collections before calling TriggerFactory.execute() with the handler object. If you want to create a manual run of the Trigger Handler without actually calling the Trigger (for example for unit testing), simply use the class method fillTriggerCollections(newList, newMap, oldList, oldMap) . In practice you may want to use the triggerNew list in your queries to create a Map, for example like this: public override void bulkBefore (){ mapIdToOppWithRelated = new Map < Id , Opportunity > ( [ SELECT Id , Account . Name , Account . ShippingCountry FROM Opportunity WHERE Id IN : triggerNew ] ); } Custom Metadata Based Triggers The Trigger Factory Setting Metadata Type prescribes the Objects, the Classes and the order of execution that the Handlers should run in. This is especially useful for very loaded objects, where we usually only require a fraction of the functionality depending on the type of record we are processing (ref. Record Type Filtering ). This also enables you to use SFDX Trigger Factory in a package-based development model where the Trigger Factory is a part of a larger package landscape. Packages can be developed independently from one another and only the Factory Setting is necessary for the factory package to recognize that a Trigger has to be executed. Therefore, the Apex Trigger is only required in one of the packages (preferably the one that contains the most dependencies). If your Object is package-exclusive - even easier! Just include both Apex Trigger and Factory Setting in your package. An example Trigger Factory Setting would look something like this: { \"Label\" : \"Opportunity General Handler\" , \"DeveloperName\" : \"OpportunityGeneralHandler\" , \"ClassName__c\" : \"OpportunityHandler\" , \"SObjectName__c\" : \"Opportunity\" , \"OrderOfExecution__c\" : 1 , \"IsDisabled__c\" : false } This would call the OpportunityHandler class at runtime. Temporarily Disable Your Triggers in Settings and Code Custom Setting The TriggerSettings__c custom settings gives you the option to disable all triggers for either the entire org, a single profile or a single user. As such, it functions as a complete killswitch, if you are for example riding on a Data Migration User Profile that is already delivering complete data to you. However, you can also selectively disable Objects and/or Trigger Handlers by inserting their names into the Text Area fields with the corresponding name. Should the space not fit, let me know! It's not intended to be used for the disablement of more than, say, two or three Classes at the same time, but there should be options to extend the functionality across multiple fields for you. Apex disableClass(String className) and disableObject(SObjectType sobjType) as well as their counterparts enableClass() and enableObject() can be used from within your Apex executions to disable Triggers from running in just the transaction that calls the method. Any other apex executions that do not come across this line of code will be unaffected. Use this if you are planning a big data update on an object that you do not need the automations of when running the update. Filter your Records before the Handler runs Record Types often serve vastly different business uses, and standard trigger logic therefore often has to make the explicit distinction between RecordTypeId A and RecordTypeId B when checking if certain pieces of functionality should be executed. Instead you can already specify one or multiple Record Type Ids in the Trigger Factory Setting . The class variables triggerNew etc. will then have only the records with the matching record types. This saves you the trouble of checking them in every method you run across. Adjusting the above example, it could look like this: { \"Label\" : \"Existing Business Opportunity Handler\" , \"DeveloperName\" : \"ExistingBusinessOppHandler\" , \"ClassName__c\" : \"ExistingBusinessOppHandler\" , \"SObjectName__c\" : \"Opportunity\" , \"OrderOfExecution__c\" : 2 , \"IsDisabled__c\" : false , \"RecordTypeIds__c\" : \"18-digit Salesforce Id\" } This Opp Handler would run after OpportunityHandler because the OrderOfExecution__c is lower. It would also only contain records that have the correct Record Type Id. Store Database Operations directly in your Handler Out of the box, this framework brings you four lists that you can leverage to collect database operations instead of calling DML all at once: lstUpdate lstInsert lstUpsert lstDelete You can use these out-of-the-box collections to perform DML in andFinally() . Please note however that should the contents of these lists not be ordered by SObject Type, that each break in the Typing will cause another DML statement . If you want to bundle based on SObject Type, either sort the list beforehand or leverage another pattern such as the lovely Unit of Work . Control Recursion (WIP) This trigger framework presents you with the option of setting a maximum LoopCount. This count will be increased everytime a Trigger is entering the BEFORE context. When the maximum Loop Count is exceeded, an exception is thrown. For example, use this.setMaxLoopCount(1) in the Trigger Constructor to make sure that the code breaks if the Trigger Handler runs more than once. Work In Progress: Soon there will be an option to gracefully skip Triggers when the Loop Count is exceeded instead of throwing an Exception.","title":"Features"},{"location":"features/#features","text":"The framework comes with a variety of features that you can leverage to your liking.","title":"Features"},{"location":"features/#trigger-collections-delivered-to-your-class","text":"The virtual class TriggerHandlerExtension that is your Trigger Handler class base offers you the following variables: triggerNew triggerNewMap triggerOld triggerOldMap To use in your bulkBefore / bulkAfter calls (as they are already leveraged in the single-record methods). This makes it possible to mock a run of a trigger by simply filling in these collections before calling TriggerFactory.execute() with the handler object. If you want to create a manual run of the Trigger Handler without actually calling the Trigger (for example for unit testing), simply use the class method fillTriggerCollections(newList, newMap, oldList, oldMap) . In practice you may want to use the triggerNew list in your queries to create a Map, for example like this: public override void bulkBefore (){ mapIdToOppWithRelated = new Map < Id , Opportunity > ( [ SELECT Id , Account . Name , Account . ShippingCountry FROM Opportunity WHERE Id IN : triggerNew ] ); }","title":"Trigger collections delivered to your class"},{"location":"features/#custom-metadata-based-triggers","text":"The Trigger Factory Setting Metadata Type prescribes the Objects, the Classes and the order of execution that the Handlers should run in. This is especially useful for very loaded objects, where we usually only require a fraction of the functionality depending on the type of record we are processing (ref. Record Type Filtering ). This also enables you to use SFDX Trigger Factory in a package-based development model where the Trigger Factory is a part of a larger package landscape. Packages can be developed independently from one another and only the Factory Setting is necessary for the factory package to recognize that a Trigger has to be executed. Therefore, the Apex Trigger is only required in one of the packages (preferably the one that contains the most dependencies). If your Object is package-exclusive - even easier! Just include both Apex Trigger and Factory Setting in your package. An example Trigger Factory Setting would look something like this: { \"Label\" : \"Opportunity General Handler\" , \"DeveloperName\" : \"OpportunityGeneralHandler\" , \"ClassName__c\" : \"OpportunityHandler\" , \"SObjectName__c\" : \"Opportunity\" , \"OrderOfExecution__c\" : 1 , \"IsDisabled__c\" : false } This would call the OpportunityHandler class at runtime.","title":"Custom Metadata Based Triggers"},{"location":"features/#temporarily-disable-your-triggers-in-settings-and-code","text":"","title":"Temporarily Disable Your Triggers in Settings and Code"},{"location":"features/#custom-setting","text":"The TriggerSettings__c custom settings gives you the option to disable all triggers for either the entire org, a single profile or a single user. As such, it functions as a complete killswitch, if you are for example riding on a Data Migration User Profile that is already delivering complete data to you. However, you can also selectively disable Objects and/or Trigger Handlers by inserting their names into the Text Area fields with the corresponding name. Should the space not fit, let me know! It's not intended to be used for the disablement of more than, say, two or three Classes at the same time, but there should be options to extend the functionality across multiple fields for you.","title":"Custom Setting"},{"location":"features/#apex","text":"disableClass(String className) and disableObject(SObjectType sobjType) as well as their counterparts enableClass() and enableObject() can be used from within your Apex executions to disable Triggers from running in just the transaction that calls the method. Any other apex executions that do not come across this line of code will be unaffected. Use this if you are planning a big data update on an object that you do not need the automations of when running the update.","title":"Apex"},{"location":"features/#filter-your-records-before-the-handler-runs","text":"Record Types often serve vastly different business uses, and standard trigger logic therefore often has to make the explicit distinction between RecordTypeId A and RecordTypeId B when checking if certain pieces of functionality should be executed. Instead you can already specify one or multiple Record Type Ids in the Trigger Factory Setting . The class variables triggerNew etc. will then have only the records with the matching record types. This saves you the trouble of checking them in every method you run across. Adjusting the above example, it could look like this: { \"Label\" : \"Existing Business Opportunity Handler\" , \"DeveloperName\" : \"ExistingBusinessOppHandler\" , \"ClassName__c\" : \"ExistingBusinessOppHandler\" , \"SObjectName__c\" : \"Opportunity\" , \"OrderOfExecution__c\" : 2 , \"IsDisabled__c\" : false , \"RecordTypeIds__c\" : \"18-digit Salesforce Id\" } This Opp Handler would run after OpportunityHandler because the OrderOfExecution__c is lower. It would also only contain records that have the correct Record Type Id.","title":"Filter your Records before the Handler runs"},{"location":"features/#store-database-operations-directly-in-your-handler","text":"Out of the box, this framework brings you four lists that you can leverage to collect database operations instead of calling DML all at once: lstUpdate lstInsert lstUpsert lstDelete You can use these out-of-the-box collections to perform DML in andFinally() . Please note however that should the contents of these lists not be ordered by SObject Type, that each break in the Typing will cause another DML statement . If you want to bundle based on SObject Type, either sort the list beforehand or leverage another pattern such as the lovely Unit of Work .","title":"Store Database Operations directly in your Handler"},{"location":"features/#control-recursion-wip","text":"This trigger framework presents you with the option of setting a maximum LoopCount. This count will be increased everytime a Trigger is entering the BEFORE context. When the maximum Loop Count is exceeded, an exception is thrown. For example, use this.setMaxLoopCount(1) in the Trigger Constructor to make sure that the code breaks if the Trigger Handler runs more than once. Work In Progress: Soon there will be an option to gracefully skip Triggers when the Loop Count is exceeded instead of throwing an Exception.","title":"Control Recursion (WIP)"},{"location":"installation/","text":"Installation Environment Package Type Install Link Production Unlocked Click here Sandbox Unlocked Click here Production Unmanaged Refer to README in Repository Simply click on one of the Links to install the App (it's recommended to install the Unlocked Package to easily benefit from future updates).","title":"Installation"},{"location":"installation/#installation","text":"Environment Package Type Install Link Production Unlocked Click here Sandbox Unlocked Click here Production Unmanaged Refer to README in Repository Simply click on one of the Links to install the App (it's recommended to install the Unlocked Package to easily benefit from future updates).","title":"Installation"},{"location":"order/","text":"Order of Execution Standard Order This assumes that all contexts are referenced in the Apex Trigger that calls executeTriggerHandlers . Starting Point: DML Statement is fired BEFORE CONTEXT Trigger Handler is instantiated once, constructor is called bulkBefore() is called beforeUpdate(), beforeInsert(), or beforeDelete() is called for each record from a for loop andFinally() is called AFTER CONTEXT Trigger Handler is instantiated another time, constructor is called again bulkAfter() is called afterUpdate(), afterInsert(), or afterDelete() is called for each record from a for loop andFinally() is called a second time Commit is finalized only after all of these actions have been executed. Multiple Handlers This process looks like this across more than one Trigger Handler: BEFORE CONTEXT Trigger Handler 1: BEFORE CONTEXT Trigger Handler 2: BEFORE CONTEXT Trigger Handler 3: BEFORE CONTEXT AFTER CONTEXT Trigger Handler 1: AFTER CONTEXT Trigger Handler 2: AFTER CONTEXT Trigger Handler 3: AFTER CONTEXT","title":"Order of Execution"},{"location":"order/#order-of-execution","text":"","title":"Order of Execution"},{"location":"order/#standard-order","text":"This assumes that all contexts are referenced in the Apex Trigger that calls executeTriggerHandlers . Starting Point: DML Statement is fired BEFORE CONTEXT Trigger Handler is instantiated once, constructor is called bulkBefore() is called beforeUpdate(), beforeInsert(), or beforeDelete() is called for each record from a for loop andFinally() is called AFTER CONTEXT Trigger Handler is instantiated another time, constructor is called again bulkAfter() is called afterUpdate(), afterInsert(), or afterDelete() is called for each record from a for loop andFinally() is called a second time Commit is finalized only after all of these actions have been executed.","title":"Standard Order"},{"location":"order/#multiple-handlers","text":"This process looks like this across more than one Trigger Handler: BEFORE CONTEXT Trigger Handler 1: BEFORE CONTEXT Trigger Handler 2: BEFORE CONTEXT Trigger Handler 3: BEFORE CONTEXT AFTER CONTEXT Trigger Handler 1: AFTER CONTEXT Trigger Handler 2: AFTER CONTEXT Trigger Handler 3: AFTER CONTEXT","title":"Multiple Handlers"},{"location":"structure/","text":"Structural Examples Entry-Level Org with low amount of automation In an org where the amount of automations is still very easy to oversee, the quickest way from installation of the framework to working functionality is to create a method inside the Trigger Handler and simply call it in your triggering method. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class OpportunityHandler extends TriggerHandlerExtension { public OpportunityHandler (){ super (); } public override beforeUpdate ( SObject oldSObj , SObject newSObj ){ Opportunity oldOpp = ( Opportunity ) oldSObj ; Opportunity newOpp = ( Opportunity ) newSObj ; setCloseDateForWonOpp ( oldOpp , newOpp ); } @TestVisible private void setCloseDateForWonOpp ( Opportunity oldOpp , Opportunity , newOpp ){ if ( oldOpp . StageName != newOpp . StageName && newOpp . StageName == ' Closed Won ' ){ newOpp . CloseDate = Date . today (); } } } Mid-size Org with medium to high amounts of automation Once automations grow, it is hard to oversee everything from within the same class. Editing the same class in multiple development streams and git branches at the same time become more and more likely. In such cases, it is recommended to switch to helper classes that leverage module-level code and make it easier to separate trigger logistics from trigger logic . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class OpportunityHandler extends TriggerHandlerExtension { OpportunityDataRefinementHelper helper ; OpprotunityAfterSalesHelper afterSalesHelper ; public OpportunityHandler (){ super (); helper = new OpportunityDataRefinementHelper ( triggerNew , triggerNewMap , triggerOld , triggerOldMap ); afterSalesHelper = new OpprotunityAfterSalesHelper ( triggerNew , triggerNewMap , triggerOld , triggerOldMap ); } public override bulkBefore (){ afterSalesHelper . fetchDataIntoMapsBeforeUpdate (); } public override beforeUpdate ( SObject oldSObj , SObject newSObj ){ Opportunity oldOpp = ( Opportunity ) oldSObj ; Opportunity newOpp = ( Opportunity ) newSObj ; helper . setCloseDateForWonOpp ( oldOpp , newOpp ); } //and so on. } Enterprise-level org / org with high density of automations An org does not need to be enterprise-level to have a high density of automations on the same object. To the contrary, some smaller customers that use the same objects for a multitude of different use cases may very quickly grow out of the above patterns due to new requirements growing out of the framework like weed beneath the pavement. In these cases, I recommend to approach triggers with a SOLID approach. While we are not able to completely cover all of these aspects in Apex, we can at least approach them with a clear separation of concerns, for example by giving each Data Processing Function its own class. These classes can in turn access another class that contains all the relevant data that has been cached by the Trigger Handler. Example with complete separation of concerns 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class OpportunityHandler extends TriggerHandlerExtension { OpportunityDataCache cache ; public OpportunityHandler (){ super (); } public override bulkBefore (){ new OpportunityClosedWonDataCacher ( cache ). run (); //This cacher class should only run if the necessary requirements are fulfilled //e.g. Trigger Context is UPDATE and at least one Opportunity in context has been set to Closed Won } public override beforeUpdate ( SObject oldSObj , SObject newSObj ){ Opportunity oldOpp = ( Opportunity ) oldSObj ; Opportunity newOpp = ( Opportunity ) newSObj ; new OpportunitySetFieldsForClosedWon (). run ( oldOpp , newOpp ); //This class would only set fields on the triggering records, not requiring the cache at all. } public override afterUpdate ( SObject oldSObj , SObject newSObj ){ Opportunity oldOpp = ( Opportunity ) oldSObj ; Opportunity newOpp = ( Opportunity ) newSObj ; new OpportunityAfterSalesActivities ( cache ). run ( oldOpp , newOpp ); //This class would access data in cache where needed to create new records and update existing ones. //This in turn would be handled with a Unit of Work here. } //and so on. }","title":"Structural Examples"},{"location":"structure/#structural-examples","text":"","title":"Structural Examples"},{"location":"structure/#entry-level-org-with-low-amount-of-automation","text":"In an org where the amount of automations is still very easy to oversee, the quickest way from installation of the framework to working functionality is to create a method inside the Trigger Handler and simply call it in your triggering method. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class OpportunityHandler extends TriggerHandlerExtension { public OpportunityHandler (){ super (); } public override beforeUpdate ( SObject oldSObj , SObject newSObj ){ Opportunity oldOpp = ( Opportunity ) oldSObj ; Opportunity newOpp = ( Opportunity ) newSObj ; setCloseDateForWonOpp ( oldOpp , newOpp ); } @TestVisible private void setCloseDateForWonOpp ( Opportunity oldOpp , Opportunity , newOpp ){ if ( oldOpp . StageName != newOpp . StageName && newOpp . StageName == ' Closed Won ' ){ newOpp . CloseDate = Date . today (); } } }","title":"Entry-Level Org with low amount of automation"},{"location":"structure/#mid-size-org-with-medium-to-high-amounts-of-automation","text":"Once automations grow, it is hard to oversee everything from within the same class. Editing the same class in multiple development streams and git branches at the same time become more and more likely. In such cases, it is recommended to switch to helper classes that leverage module-level code and make it easier to separate trigger logistics from trigger logic . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class OpportunityHandler extends TriggerHandlerExtension { OpportunityDataRefinementHelper helper ; OpprotunityAfterSalesHelper afterSalesHelper ; public OpportunityHandler (){ super (); helper = new OpportunityDataRefinementHelper ( triggerNew , triggerNewMap , triggerOld , triggerOldMap ); afterSalesHelper = new OpprotunityAfterSalesHelper ( triggerNew , triggerNewMap , triggerOld , triggerOldMap ); } public override bulkBefore (){ afterSalesHelper . fetchDataIntoMapsBeforeUpdate (); } public override beforeUpdate ( SObject oldSObj , SObject newSObj ){ Opportunity oldOpp = ( Opportunity ) oldSObj ; Opportunity newOpp = ( Opportunity ) newSObj ; helper . setCloseDateForWonOpp ( oldOpp , newOpp ); } //and so on. }","title":"Mid-size Org with medium to high amounts of automation"},{"location":"structure/#enterprise-level-org-org-with-high-density-of-automations","text":"An org does not need to be enterprise-level to have a high density of automations on the same object. To the contrary, some smaller customers that use the same objects for a multitude of different use cases may very quickly grow out of the above patterns due to new requirements growing out of the framework like weed beneath the pavement. In these cases, I recommend to approach triggers with a SOLID approach. While we are not able to completely cover all of these aspects in Apex, we can at least approach them with a clear separation of concerns, for example by giving each Data Processing Function its own class. These classes can in turn access another class that contains all the relevant data that has been cached by the Trigger Handler. Example with complete separation of concerns 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class OpportunityHandler extends TriggerHandlerExtension { OpportunityDataCache cache ; public OpportunityHandler (){ super (); } public override bulkBefore (){ new OpportunityClosedWonDataCacher ( cache ). run (); //This cacher class should only run if the necessary requirements are fulfilled //e.g. Trigger Context is UPDATE and at least one Opportunity in context has been set to Closed Won } public override beforeUpdate ( SObject oldSObj , SObject newSObj ){ Opportunity oldOpp = ( Opportunity ) oldSObj ; Opportunity newOpp = ( Opportunity ) newSObj ; new OpportunitySetFieldsForClosedWon (). run ( oldOpp , newOpp ); //This class would only set fields on the triggering records, not requiring the cache at all. } public override afterUpdate ( SObject oldSObj , SObject newSObj ){ Opportunity oldOpp = ( Opportunity ) oldSObj ; Opportunity newOpp = ( Opportunity ) newSObj ; new OpportunityAfterSalesActivities ( cache ). run ( oldOpp , newOpp ); //This class would access data in cache where needed to create new records and update existing ones. //This in turn would be handled with a Unit of Work here. } //and so on. }","title":"Enterprise-level org / org with high density of automations"},{"location":"use/","text":"How to use Step-by-Step Guide Step 1: Install the Framework Well, obviously you need the framework to start working with it. :) Head over to Installation to find the correct version for you. Step 2: Create a Trigger Handler and have it extend TriggerHandlerExension You need to create the class the TriggerFactory instantiates. The factory expects classes of Type TriggerHandlerExtension , so to get started, use the newly installed virtual class in your own Handler class. Make sure to call super() in your constructor, or else all other functionality (including actually using the Trigger Collections ) will not work. public class ExampleTriggerHandler extends TriggerHandlerExtension { public ExampleTriggerHandler (){ super (); } } Step 3: Create a Trigger Should an Apex Trigger not exist yet, you should definitely create a Trigger right about now. Make sure to include all contexts ( except when handling Platform Events ) and call TriggerFactory.executeTriggerHandlers(SOBJECT_TYPE_OF_YOUR_TRIGGERING_OBJECT) . trigger AccountTrigger on Account ( before insert , after insert , before update , after update , before delete , after delete , after undelete ) { TriggerFactory . executeTriggerHandlers ( Account . SObjectType ); } Step 4: Create a Trigger Factory Setting In order to make the Trigger run, you need to create a Custom Metadata Record for the Handler you are working on. For more about the Custom Metadata driven trigger execution, check out the feature page Step 5: Add functionality This step is different depending on the size of your org and the structure of your other Triggers, so this is left very vague on purpose. Check Structural examples to find out what approach fits your org best. Step 6: You're done! What happens next is up to the rest of ongoing development - Test and Release your Triggers and start your next automation!","title":"How to use"},{"location":"use/#how-to-use","text":"","title":"How to use"},{"location":"use/#step-by-step-guide","text":"","title":"Step-by-Step Guide"},{"location":"use/#step-1-install-the-framework","text":"Well, obviously you need the framework to start working with it. :) Head over to Installation to find the correct version for you.","title":"Step 1: Install the Framework"},{"location":"use/#step-2-create-a-trigger-handler-and-have-it-extend-triggerhandlerexension","text":"You need to create the class the TriggerFactory instantiates. The factory expects classes of Type TriggerHandlerExtension , so to get started, use the newly installed virtual class in your own Handler class. Make sure to call super() in your constructor, or else all other functionality (including actually using the Trigger Collections ) will not work. public class ExampleTriggerHandler extends TriggerHandlerExtension { public ExampleTriggerHandler (){ super (); } }","title":"Step 2: Create a Trigger Handler and have it extend TriggerHandlerExension"},{"location":"use/#step-3-create-a-trigger","text":"Should an Apex Trigger not exist yet, you should definitely create a Trigger right about now. Make sure to include all contexts ( except when handling Platform Events ) and call TriggerFactory.executeTriggerHandlers(SOBJECT_TYPE_OF_YOUR_TRIGGERING_OBJECT) . trigger AccountTrigger on Account ( before insert , after insert , before update , after update , before delete , after delete , after undelete ) { TriggerFactory . executeTriggerHandlers ( Account . SObjectType ); }","title":"Step 3: Create a Trigger"},{"location":"use/#step-4-create-a-trigger-factory-setting","text":"In order to make the Trigger run, you need to create a Custom Metadata Record for the Handler you are working on. For more about the Custom Metadata driven trigger execution, check out the feature page","title":"Step 4: Create a Trigger Factory Setting"},{"location":"use/#step-5-add-functionality","text":"This step is different depending on the size of your org and the structure of your other Triggers, so this is left very vague on purpose. Check Structural examples to find out what approach fits your org best.","title":"Step 5: Add functionality"},{"location":"use/#step-6-youre-done","text":"What happens next is up to the rest of ongoing development - Test and Release your Triggers and start your next automation!","title":"Step 6: You're done!"},{"location":"why/","text":"Why this Framework? Comparison to other frameworks Of course, the question to ask yourself is always: \"Out of all the frameworks in the world, why use this one?\" And the question is justified. There are a lot of other very good frameworks in the wild, such as Kevin O'Hara's Lightweight Trigger Framework (of which I actually recommend This fork ), or the fflib SObject Domain Pattern . Even most recently, the Apex Trigger Actions Framework has made a splash in the scene - And it's going to be really interesting to see where it leads us. However, with the exception of the Kevin O'Hara Framework, I think that these frameworks have a pretty high barrier to entry and are often dependent on the metadata being monolithic. With the exception of the Trigger Actions Framework, there is a strict requirement for the Trigger Handler to be present in the same package as the Trigger Handler. These are two things that we try to alleviate with our framework. Aims The aim of the SFDX Trigger Factory we use at mindsquare is to streamline the most common actions that a developer does and enforce clean style by making specific methods for each trigger context. It's also scalable , which is to say that it is easy to implement a very simple Trigger Handler containing only basic business logic, but it's just as well possible to scale with a lot of different modules, functions, etc, given that separation of concerns is upheld. Streamlining By streamlining, I am referring to the \" Cache - Process - Commit \" approach mentioned in the description of the repo. Each of these processes is supposed to be supported by one of the streams offered by the framework. Caching By calling either bulkBefore() or bulkAfter() we are able to prepare data by checking conditions on the records in our Trigger Context. These methods are supposed to be used primarily for storing data in Maps or Lists for retrieval later on in the trigger. Alternatively, the two methods can also house bulk logic. This can be useful for grandfathering in old trigger methods into the new framework, or if your trigger is really barebones to start with. Processing Processing happens on a per-record basis. This means that the following methods: beforeInsert afterInsert beforeUpdate afterUpdate beforeDelete afterDelete afterUndelete are called separately for each record . With this in mind all bulkification is taken out of your hands here - you only need to worry about creating business logic for a single record. Additionally, it's easy to selectively add an Error message to a single record in a Trigger Context. This style also enforces that we absolutely do not use SOQL or DML in these methods. Instead we add records into collections that should later be updated / inserted / deleted. Commit andFinally() is called at the end of both the BEFORE context, as well as at the end of the AFTER context. In theory, andFinally() should also not contain any business logic, but instead focus on committing what we have edited and created to the Database . For this you can leverage the collections already offered by the Framework , or you can use your own, if you decide that you need a slightly different or more sophisticated structure.","title":"Why this Framework?"},{"location":"why/#why-this-framework","text":"","title":"Why this Framework?"},{"location":"why/#comparison-to-other-frameworks","text":"Of course, the question to ask yourself is always: \"Out of all the frameworks in the world, why use this one?\" And the question is justified. There are a lot of other very good frameworks in the wild, such as Kevin O'Hara's Lightweight Trigger Framework (of which I actually recommend This fork ), or the fflib SObject Domain Pattern . Even most recently, the Apex Trigger Actions Framework has made a splash in the scene - And it's going to be really interesting to see where it leads us. However, with the exception of the Kevin O'Hara Framework, I think that these frameworks have a pretty high barrier to entry and are often dependent on the metadata being monolithic. With the exception of the Trigger Actions Framework, there is a strict requirement for the Trigger Handler to be present in the same package as the Trigger Handler. These are two things that we try to alleviate with our framework.","title":"Comparison to other frameworks"},{"location":"why/#aims","text":"The aim of the SFDX Trigger Factory we use at mindsquare is to streamline the most common actions that a developer does and enforce clean style by making specific methods for each trigger context. It's also scalable , which is to say that it is easy to implement a very simple Trigger Handler containing only basic business logic, but it's just as well possible to scale with a lot of different modules, functions, etc, given that separation of concerns is upheld.","title":"Aims"},{"location":"why/#streamlining","text":"By streamlining, I am referring to the \" Cache - Process - Commit \" approach mentioned in the description of the repo. Each of these processes is supposed to be supported by one of the streams offered by the framework.","title":"Streamlining"},{"location":"why/#caching","text":"By calling either bulkBefore() or bulkAfter() we are able to prepare data by checking conditions on the records in our Trigger Context. These methods are supposed to be used primarily for storing data in Maps or Lists for retrieval later on in the trigger. Alternatively, the two methods can also house bulk logic. This can be useful for grandfathering in old trigger methods into the new framework, or if your trigger is really barebones to start with.","title":"Caching"},{"location":"why/#processing","text":"Processing happens on a per-record basis. This means that the following methods: beforeInsert afterInsert beforeUpdate afterUpdate beforeDelete afterDelete afterUndelete are called separately for each record . With this in mind all bulkification is taken out of your hands here - you only need to worry about creating business logic for a single record. Additionally, it's easy to selectively add an Error message to a single record in a Trigger Context. This style also enforces that we absolutely do not use SOQL or DML in these methods. Instead we add records into collections that should later be updated / inserted / deleted.","title":"Processing"},{"location":"why/#commit","text":"andFinally() is called at the end of both the BEFORE context, as well as at the end of the AFTER context. In theory, andFinally() should also not contain any business logic, but instead focus on committing what we have edited and created to the Database . For this you can leverage the collections already offered by the Framework , or you can use your own, if you decide that you need a slightly different or more sophisticated structure.","title":"Commit"}]}